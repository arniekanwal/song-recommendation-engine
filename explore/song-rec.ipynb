{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import any necessary libraries / modules\n",
    "import os\n",
    "import sys\n",
    "import timeit\n",
    "\n",
    "import pandas as pd # we only use pandas as examples to compare to\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lower, when, split\n",
    "from pyspark.sql.types import IntegerType, FloatType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../datasets/tracks_features.csv\n",
      "Time taken with PySpark: 1.3483 seconds\n",
      "Time taken with Pandas: 3.2269 seconds\n"
     ]
    }
   ],
   "source": [
    "# Create a path to the dataset and read into our Spark Session\n",
    "\n",
    "DATA_PATH = os.path.join(\"..\", \"datasets\", \"tracks_features.csv\")\n",
    "print(DATA_PATH)\n",
    "\n",
    "spark = SparkSession.builder.appName(\"SongRecommendation\").getOrCreate()\n",
    "\n",
    "'''\n",
    "First exercise is to just compare execution time between Pandas and PySpark...\n",
    "\n",
    "There is already a meaningful difference due to dataset size of 1.2million rows, but remember \n",
    "that Spark is being run locally (single cluster) and our dataset is still relatively small \n",
    "(i.e. 350mb vs hundreds of gigs or tb in real-world applications)\n",
    "'''\n",
    "# Function to read with PySpark\n",
    "def read_with_spark():\n",
    "    df = spark.read.csv(DATA_PATH)\n",
    "\n",
    "# Function to read with Pandas\n",
    "def read_with_pandas():\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Measure execution time\n",
    "spark_time = timeit.timeit(read_with_spark, number=1)  # Run once\n",
    "pandas_time = timeit.timeit(read_with_pandas, number=1)  # Run once\n",
    "\n",
    "# Print results\n",
    "print(f\"Time taken with PySpark: {spark_time:.4f} seconds\")\n",
    "print(f\"Time taken with Pandas: {pandas_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------+-----------+--------+------------+------------------+---+-------------------+----+-----------+------------+----------------+-------------------+-------+-----------------+-----------+--------------+----+------------+\n",
      "|                  id|                name|               album|            album_id|             artists|          artist_ids|track_number|disc_number|explicit|danceability|            energy|key|           loudness|mode|speechiness|acousticness|instrumentalness|           liveness|valence|            tempo|duration_ms|time_signature|year|release_date|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------+-----------+--------+------------+------------------+---+-------------------+----+-----------+------------+----------------+-------------------+-------+-----------------+-----------+--------------+----+------------+\n",
      "|7lmeHLHBe4nmXzuXc...|             Testify|The Battle Of Los...|2eia0myWFgoHuttJy...|['Rage Against Th...|['2d0hyoQ5ynDBnkv...|           1|          1|   False|        0.47|             0.978|  7|             -5.399|   1|     0.0727|      0.0261|        1.09e-05|0.35600000000000004|  0.503|          117.906|     210133|           4.0|1999|  1999-11-02|\n",
      "|1wsRitfRRtWyEapl0...|     Guerrilla Radio|The Battle Of Los...|2eia0myWFgoHuttJy...|['Rage Against Th...|['2d0hyoQ5ynDBnkv...|           2|          1|    True|       0.599|0.9570000000000001| 11| -5.763999999999999|   1|      0.188|      0.0129|        7.06e-05|              0.155|  0.489|           103.68|     206200|           4.0|1999|  1999-11-02|\n",
      "|1hR0fIFK2qRG3f3RF...|    Calm Like a Bomb|The Battle Of Los...|2eia0myWFgoHuttJy...|['Rage Against Th...|['2d0hyoQ5ynDBnkv...|           3|          1|   False|       0.315|              0.97|  7|-5.4239999999999995|   1|      0.483|      0.0234|        2.03e-06|              0.122|   0.37|          149.749|     298893|           4.0|1999|  1999-11-02|\n",
      "|2lbASgTSoDO7MTuLA...|           Mic Check|The Battle Of Los...|2eia0myWFgoHuttJy...|['Rage Against Th...|['2d0hyoQ5ynDBnkv...|           4|          1|    True|        0.44|0.9670000000000001| 11|              -5.83|   0|      0.237|       0.163|        3.64e-06|              0.121|  0.574|96.75200000000001|     213640|           4.0|1999|  1999-11-02|\n",
      "|1MQTmpYOZ6fcMQc56...|Sleep Now In the ...|The Battle Of Los...|2eia0myWFgoHuttJy...|['Rage Against Th...|['2d0hyoQ5ynDBnkv...|           5|          1|   False|       0.426|             0.929|  2|             -6.729|   1|     0.0701|     0.00162|           0.105|             0.0789|  0.539|          127.059|     205600|           4.0|1999|  1999-11-02|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------+-----------+--------+------------+------------------+---+-------------------+----+-----------+------------+----------------+-------------------+-------+-----------------+-----------+--------------+----+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's ready our data in memory and get ready for data processing\n",
    "df = spark.read.csv(DATA_PATH, header=True, inferSchema=True)\n",
    "# Show the first 5 tracks\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data contains 1204025 rows and 24 cols\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- album: string (nullable = true)\n",
      " |-- album_id: string (nullable = true)\n",
      " |-- artists: string (nullable = true)\n",
      " |-- artist_ids: string (nullable = true)\n",
      " |-- track_number: string (nullable = true)\n",
      " |-- disc_number: string (nullable = true)\n",
      " |-- explicit: string (nullable = true)\n",
      " |-- danceability: string (nullable = true)\n",
      " |-- energy: string (nullable = true)\n",
      " |-- key: string (nullable = true)\n",
      " |-- loudness: string (nullable = true)\n",
      " |-- mode: string (nullable = true)\n",
      " |-- speechiness: string (nullable = true)\n",
      " |-- acousticness: string (nullable = true)\n",
      " |-- instrumentalness: string (nullable = true)\n",
      " |-- liveness: string (nullable = true)\n",
      " |-- valence: string (nullable = true)\n",
      " |-- tempo: string (nullable = true)\n",
      " |-- duration_ms: string (nullable = true)\n",
      " |-- time_signature: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- release_date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Collect general information on original dataset\n",
    "nrows, ncols = df.count(), len(df.columns)\n",
    "print(f\"Data contains {nrows} rows and {ncols} cols\")\n",
    "df.printSchema() # <-- uh-oh, all data types are string...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 186:============================================>            (7 + 2) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data contains 1138490 rows and 24 cols\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Drop rows with missing values and drop duplicate rows w/ matching artist_ids and case-insensitive names\n",
    "\n",
    "NOTE: .count() requires computation across whole cluster, so probably inefficient in real \n",
    "world to query often \n",
    "'''\n",
    "\n",
    "df = (df\n",
    "      .dropna()\n",
    "      .withColumn(\"name_lower\", lower(col(\"name\")))\n",
    "      .dropDuplicates([\"name_lower\", \"artist_ids\"])\n",
    "      .drop(\"name_lower\")\n",
    ")\n",
    "\n",
    "nrows, ncols = df.count(), len(df.columns)            \n",
    "print(f\"Data contains {nrows} rows and {ncols} cols\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We were unable to infer the schema when reading the CSV with PySpark\n",
    "# Let's cast these columns to their correct types\n",
    "\n",
    "# Cast explicit to an IntType\n",
    "bool_col = \"explicit\"\n",
    "df = df.withColumn(bool_col, when(col(bool_col) == \"True\", 1)\n",
    "                                    .when(col(bool_col) == \"False\", 0)\n",
    "                                    .otherwise(0)) \n",
    "\n",
    "# Convert string representation of list into array of strings\n",
    "df = df.withColumn(\"artists\", split(col(\"artists\"), \",\\s*\")) \\\n",
    "       .withColumn(\"artist_ids\", split(col(\"artist_ids\"), \",\\s*\"))\n",
    "\n",
    "# Cast the other numerical columns\n",
    "int_cols = [\"track_number\", \"disc_number\", \"key\", \"mode\", \"duration_ms\", \"year\"]\n",
    "float_cols = [\"danceability\", \"energy\", \"loudness\", \"speechiness\", \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\", \"tempo\", \"time_signature\"]\n",
    "\n",
    "for col_name in int_cols:\n",
    "    df = df.withColumn(col_name, col(col_name).cast(IntegerType()))\n",
    "\n",
    "for col_name in float_cols:\n",
    "    df = df.withColumn(col_name, col(col_name).cast(FloatType()))\n",
    "\n",
    "df.printSchema()\n",
    "df.show(5)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
